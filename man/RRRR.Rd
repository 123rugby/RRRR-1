% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RRRR.R
\name{RRRR}
\alias{RRRR}
\title{Robust Reduced-Rank Regression using Majorization-Minimization}
\source{
Z. Zhao and D. P. Palomar, “Robust maximum likelihood estimation of sparse vector error correction model,” in2017 IEEE Global Conferenceon Signal and Information Processing (GlobalSIP),  pp.  913—-917,IEEE, 2017.
}
\usage{
RRRR(
  y,
  x,
  z = NULL,
  mu = TRUE,
  r = 1,
  itr = 100,
  earlystop = 1e-04,
  initial_A = matrix(rnorm(P * r), ncol = r),
  initial_B = matrix(rnorm(Q * r), ncol = r),
  initial_D = matrix(rnorm(P * (R + 1)), ncol = R + 1),
  initial_Sigma = diag(P)
)
}
\arguments{
\item{y}{Matrix of dimension N*P. The matrix for the response variables. See \code{Detail}.}

\item{x}{Matrix of dimension N*Q. The matrix for the explanatory variables to be projected. See \code{Detail}.}

\item{z}{Matrix of dimension N*R. The matrix for the explanatory variables not to be projected. See \code{Detail}.}

\item{mu}{Logical. Indicating if a constant term is included.}

\item{r}{Integer. The rank for the reduced-rank matrix \eqn{AB'}. See \code{Detail}.}

\item{itr}{Interger. The maximum number of iteration.}

\item{earlystop}{Scalar. The criteria to stop the algorithm early. The algorithm will stop if the improvement
on objective function is small than \eqn{earlystop * objective_from_last_iteration}.}
}
\value{
A list of the estimated parameters of class \code{RRR}.
\describe{
\item{spec}{The input specifications. \eqn{N} is the sample size.}
\item{mu}{The estimated constant vector. Can be \code{NULL}.}
\item{A}{The estimated exposure matrix.}
\item{B}{The estimated factor matrix.}
\item{D}{The estimated coefficient matrix of \code{z}.}
\item{Sigma}{The estimated covariance matrix of the innovarion distribution.}
}
}
\description{
Majorization-Minimization based Estimation for Reduced-Rank Regression with a Cauchy Distribution Assumption
This method is robust in the sense that it assumes a heavy-tailed Cauchy distribution
for the innovations. This method is an iterative optimization algorithm. See \code{source} for a similar setting.
}
\details{
The fomulation of the reduced-rank regression is as follow:
\deqn{y = \mu +AB'  x + D z+innov,}
where for each realization \eqn{y} is a vector of dimension \eqn{P} for the \eqn{P} response variables,
\eqn{x} is a vector of dimension \eqn{Q} for the \eqn{Q} explanatory variables that will be projected to
reduce the rank,
\eqn{z} is a vector of dimension \eqn{R} for the \eqn{R} explanatory variables
that will not be projected,
\eqn{\mu} is the constant vector of dimension \eqn{P},
\eqn{innov} is the innovation vector of dimension \eqn{P},
\eqn{D} is a coefficient matrix for \eqn{z} with dimension \eqn{P*R},
\eqn{A} is the so called exposure matrix with dimension \eqn{P*r}, and
\eqn{B} is the so called factor matrix with dimension \eqn{Q*r}.
The matrix resulted from \eqn{AB'} will be a reduced rank coefficient matrix with rank of \eqn{r}.
The function estimates parameters \eqn{\mu}, \eqn{A}, \eqn{B}, \eqn{D}, and \eqn{Sigma}, the covariance matrix of
the innovation's distribution, assuming the innovation has a Gaussian distribution.
}
\examples{
set.seed(2222)
data <- RRR_sim()
res <- RRR(y=data$y, x=data$x, z = data$z)
res

}
\author{
Yangzhuoran Yang
}
